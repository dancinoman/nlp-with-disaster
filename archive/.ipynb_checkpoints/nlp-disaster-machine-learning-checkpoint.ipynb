{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b96c3c8-fef5-4172-ac1e-16d4af84f1cc",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cc7ea-8ade-4a2a-acb3-5b38676a6b6f",
   "metadata": {},
   "source": [
    "This is the link of the competition: https://www.kaggle.com/competitions/nlp-getting-started/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98733383-a8ec-4fdb-bb03-3589ce2a6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848df5a3-ce58-47ea-9d7e-a1ab89b99b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the sample format way to submit the contest\n",
    "file_loc = '../data/sample_submission.csv'\n",
    "df = pd.read_csv(file_loc)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33beba11-c8b7-45e3-84b2-6b5dc0a93886",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5d1a3b-670a-454c-8d98-7c1848eeade1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "file_loc_train = '../data/train.csv'\n",
    "file_loc_test = '../data/test.csv'\n",
    "df = pd.read_csv(file_loc_train)\n",
    "df_test = pd.read_csv(file_loc_test)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea09050-9dda-4f3e-9797-ac8e23d4c89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                              Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
       "1                                                                                                             Forest fire near La Ronge Sask. Canada\n",
       "2              All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
       "3                                                                                  13,000 people receive #wildfires evacuation orders in California \n",
       "4                                                           Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
       "5                                     #RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\n",
       "6                                                    #flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas\n",
       "7                                                                                        I'm on top of the hill and I can see a fire in the woods...\n",
       "8                                                                    There's an emergency evacuation happening now in the building across the street\n",
       "9                                                                                               I'm afraid that the tornado is coming to our area...\n",
       "10                                                                                                       Three people died from the heat wave so far\n",
       "11                 Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding\n",
       "12                                                                      #raining #flooding #Florida #TampaBay #Tampa 18 or 19 days. I've lost count \n",
       "13                                                                                                           #Flood in Bago Myanmar #We arrived Bago\n",
       "14                                                                                          Damage to school bus on 80 in multi car crash #BREAKING \n",
       "31                                                                                           @bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C\n",
       "33                                                                #AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi\n",
       "37                                                                                           INEC Office in Abia Set Ablaze - http://t.co/3ImaomknnA\n",
       "38      Barbados #Bridgetown JAMAICA ÛÒ Two cars set ablaze: SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J\n",
       "46                                                 How the West was burned: Thousands of wildfires ablaze in California alone http://t.co/vl5TBR3wbr\n",
       "50                                                                         Deputies: Man shot before Brighton home set ablaze http://t.co/gWNRhMSO8k\n",
       "51                                                                      Man wife get six years jail for setting ablaze niece\\nhttp://t.co/eV1ahOUCZA\n",
       "53                                                   Police: Arsonist Deliberately Set Black Church In North CarolinaåÊAblaze http://t.co/pcXarbH9An\n",
       "55           #Kurds trampling on Turkmen flag later set it ablaze while others vandalized offices of Turkmen Front in #Diyala http://t.co/4IzFdYC3cg\n",
       "56                                                 TRUCK ABLAZE : R21. VOORTREKKER AVE. OUTSIDE OR TAMBO INTL. CARGO SECTION. http://t.co/8kscqKfKkF\n",
       "59        How the West was burned: Thousands of wildfires ablaze in #California alone http://t.co/iCSjGZ9tE1 #climate #energy http://t.co/9FxmN0l0Bd\n",
       "63        @Navista7 Steve these fires out here are something else! California is a tinderbox - and this clown was setting my 'hood ablaze @News24680\n",
       "65                                                                      @nxwestmidlands huge fire at Wholesale markets ablaze http://t.co/rwzbFVNXER\n",
       "68                                                Accident on I-24 W #NashvilleTraffic. Traffic moving 8m slower than usual. https://t.co/0GHk693EgJ\n",
       "69                       Accident center lane blocked in #SantaClara on US-101 NB before Great America Pkwy #BayArea #Traffic http://t.co/pmlOhZuRWR\n",
       "72       Reported motor vehicle accident in Curry on Herman Rd near Stephenson involving an overturned vehicle. Please use... http://t.co/YbJezKuRW1\n",
       "73                                                                                                               BigRigRadio Live Accident Awareness\n",
       "74                                                        I-77 Mile Marker 31 South Mooresville  Iredell Vehicle Accident Ramp Closed at 8/6 1:18 PM\n",
       "77                                                                               Traffic accident N CABRILLO HWY/MAGELLAN AV MIR (08/06/15 11:03:58)\n",
       "78                                                   I-77 Mile Marker 31 to 40 South Mooresville  Iredell Vehicle Accident Congestion at 8/6 1:18 PM\n",
       "79                                                       the pastor was not in the scene of the accident......who was the owner of the range rover ?\n",
       "81                                                I was in a horrible car accident this past Sunday. I'm finally able to get around. Thank you GOD??\n",
       "83              #TruckCrash Overturns On #FortWorth Interstate http://t.co/Rs22LJ4qFp Click here if you've been in a crash&gt;http://t.co/Ld0unIYw4k\n",
       "84                                                                   Accident in #Ashville on US 23 SB before SR 752 #traffic http://t.co/hylMo0WgFI\n",
       "85          Carolina accident: Motorcyclist Dies in I-540 Crash With Car That Crossed Median: A motorcycle rider traveling... http://t.co/p18lzRlmy6\n",
       "86                                                                               FYI CAD:FYI: ;ACCIDENT PROPERTY DAMAGE;NHS;999 PINER RD/HORNDALE DR\n",
       "87    RT nAAYf: First accident in years. Turning onto Chandanee Magu from near MMA. Taxi rammed into me while I was halfway turned. Everyone confÛ_\n",
       "88                  Accident left lane blocked in #Manchester on Rt 293 NB before Eddy Rd stop and go traffic back to NH-3A delay of 4 mins #traffic\n",
       "89                                                                                                   ;ACCIDENT PROPERTY DAMAGE; PINER RD/HORNDALE DR\n",
       "91                                                                                         FYI CAD:FYI: ;ACCIDENT PROPERTY DAMAGE;WPD;1600 S 17TH ST\n",
       "92                                                     8/6/2015@2:09 PM: TRAFFIC ACCIDENT NO INJURY at 2781 WILLIS FOREMAN RD http://t.co/VCkIT6EDEv\n",
       "93                                                                   Aashiqui Actress Anu Aggarwal On Her Near-Fatal Accident http://t.co/6Otfp31LqW\n",
       "94                                                                                                 Suffield Alberta Accident https://t.co/bPTmlF4P10\n",
       "95        9 Mile backup on I-77 South...accident blocking the Right 2 Lanes at Exit 31 Langtree Rd...consider NC 115 or NC 150 to NC 16 as alternate\n",
       "97          #BREAKING: there was a deadly motorcycle car accident that happened to #Hagerstown today. I'll have more details at 5 @Your4State. #WHAG\n",
       "99                                                 only had a car for not even a week and got in a fucking car accident .. Mfs can't fucking drive .\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100).loc[df['target']== 1, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6d133e-57d5-4907-bf11-c3ca707e7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_w = set(stopwords.words('english'))\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    \n",
    "    wl = WordNetLemmatizer()\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower()\n",
    "    list_word = sentence.split()\n",
    "    pattern = 'http\\S+'\n",
    "    list_word = [wl.lemmatize(''.join(\n",
    "                    [\n",
    "                        c for c in char if not c.isdigit() \n",
    "                          and c not in string.punctuation\n",
    "                    ]               \n",
    "            ), pos='n' )\n",
    "        for char in list_word\n",
    "        if char not in stop_w\n",
    "        and not re.match(pattern, char)\n",
    "        ]\n",
    "    \n",
    "    return ' '.join(list_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea9ae4c-3ef5-47c3-a2c1-1f3878584829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = [preprocessing(s) for s in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77a7042-09ba-4f08-8613-ccc74fbc173e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                       deed reason earthquake may allah forgive u\n",
       "1                                                                            forest fire near la ronge sask canada\n",
       "2                            resident asked shelter place notified officer evacuation shelter place order expected\n",
       "3                                                              people receive wildfire evacuation order california\n",
       "4                                                           got sent photo ruby alaska smoke wildfire pours school\n",
       "5                         rockyfire update  california hwy  closed direction due lake county fire  cafire wildfire\n",
       "6                               flood disaster heavy rain cause flash flooding street manitou colorado spring area\n",
       "7                                                                                        im top hill see fire wood\n",
       "8                                                      there emergency evacuation happening building across street\n",
       "9                                                                                    im afraid tornado coming area\n",
       "10                                                                                 three people died heat wave far\n",
       "11                     haha south tampa getting flooded hah wait second live south tampa gonna gonna fvck flooding\n",
       "12                                                    raining flooding florida tampabay tampa   day ive lost count\n",
       "13                                                                              flood bago myanmar we arrived bago\n",
       "14                                                                     damage school bus  multi car crash breaking\n",
       "31                                                                                  bbcmtd wholesale market ablaze\n",
       "33                                                            africanbaze breaking newsnigeria flag set ablaze aba\n",
       "37                                                                                    inec office abia set ablaze \n",
       "38         barbados bridgetown jamaica ûò two car set ablaze santa cruz ûó head st elizabeth police superintende\n",
       "46                                                           west burned thousand wildfire ablaze california alone\n",
       "50                                                                        deputy man shot brighton home set ablaze\n",
       "51                                                                 man wife get six year jail setting ablaze niece\n",
       "53                                            police arsonist deliberately set black church north carolinaåêablaze\n",
       "55                      kurd trampling turkmen flag later set ablaze others vandalized office turkmen front diyala\n",
       "56                                                truck ablaze  r voortrekker ave outside tambo intl cargo section\n",
       "59                                            west burned thousand wildfire ablaze california alone climate energy\n",
       "63                          navista steve fire something else california tinderbox  clown setting hood ablaze news\n",
       "65                                                                nxwestmidlands huge fire wholesale market ablaze\n",
       "68                                                     accident i w nashvilletraffic traffic moving m slower usual\n",
       "69                                 accident center lane blocked santaclara u nb great america pkwy bayarea traffic\n",
       "72         reported motor vehicle accident curry herman rd near stephenson involving overturned vehicle please use\n",
       "73                                                                             bigrigradio live accident awareness\n",
       "74                                      i mile marker  south mooresville iredell vehicle accident ramp closed   pm\n",
       "77                                                                traffic accident n cabrillo hwymagellan av mir  \n",
       "78                                      i mile marker   south mooresville iredell vehicle accident congestion   pm\n",
       "79                                                                     pastor scene accidentwho owner range rover \n",
       "81                                          horrible car accident past sunday im finally able get around thank god\n",
       "83                                           truckcrash overturn fortworth interstate click crashgthttptcolduniywk\n",
       "84                                                                             accident ashville u  sb sr  traffic\n",
       "85                         carolina accident motorcyclist dy i crash car crossed median motorcycle rider traveling\n",
       "86                                                      fyi cadfyi accident property damagenhs piner rdhorndale dr\n",
       "87    rt naayf first accident year turning onto chandanee magu near mma taxi rammed halfway turned everyone confû\n",
       "88                accident left lane blocked manchester rt  nb eddy rd stop go traffic back nha delay  min traffic\n",
       "89                                                                    accident property damage piner rdhorndale dr\n",
       "91                                                                    fyi cadfyi accident property damagewpd th st\n",
       "92                                                                   pm traffic accident injury  willis foreman rd\n",
       "93                                                                aashiqui actress anu aggarwal nearfatal accident\n",
       "94                                                                                       suffield alberta accident\n",
       "95                mile backup i southaccident blocking right  lane exit  langtree rdconsider nc  nc  nc  alternate\n",
       "97                    breaking deadly motorcycle car accident happened hagerstown today ill detail  yourstate whag\n",
       "99                                                  car even week got fucking car accident  mf cant fucking drive \n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100).loc[df['target']== 1, 'clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e722cc84-cb6d-457e-8e53-14b01053f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaallll</th>\n",
       "      <th>aaaaaand</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aaceorg</th>\n",
       "      <th>aal</th>\n",
       "      <th>aampb</th>\n",
       "      <th>aampw</th>\n",
       "      <th>aan</th>\n",
       "      <th>...</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûòthe</th>\n",
       "      <th>ûòåêcnbc</th>\n",
       "      <th>ûó</th>\n",
       "      <th>ûóbbc</th>\n",
       "      <th>ûóher</th>\n",
       "      <th>ûókody</th>\n",
       "      <th>ûónegligence</th>\n",
       "      <th>ûótech</th>\n",
       "      <th>ûówe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 15638 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aa  aaaa  aaaaaaallll  aaaaaand  aaarrrgghhh  aaceorg  aal  aampb  \\\n",
       "target                                                                       \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "...     ...   ...          ...       ...          ...      ...  ...    ...   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "1       0.0   0.0          0.0       0.0          0.0      0.0  0.0    0.0   \n",
       "\n",
       "        aampw  aan  ...   ûò  ûòthe  ûòåêcnbc   ûó  ûóbbc  ûóher  ûókody  \\\n",
       "target              ...                                                    \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "...       ...  ...  ...  ...    ...       ...  ...    ...    ...     ...   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "1         0.0  0.0  ...  0.0    0.0       0.0  0.0    0.0    0.0     0.0   \n",
       "\n",
       "        ûónegligence  ûótech  ûówe  \n",
       "target                              \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "...              ...     ...   ...  \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "1                0.0     0.0   0.0  \n",
       "\n",
       "[7613 rows x 15638 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vectorizer model\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the text data to feature vectors\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "y = df['target']\n",
    "words_weight = pd.DataFrame(X.toarray())\n",
    "words_weight.columns = vectorizer.get_feature_names_out()\n",
    "words_weight.index = y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736168ac-5205-401f-a7a5-f1761d9a7471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the classifier\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71561106-dd91-403e-adc9-3fd5bc7a3560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8021\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84      1318\n",
      "           1       0.86      0.64      0.73       966\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.82      0.78      0.79      2284\n",
      "weighted avg       0.81      0.80      0.80      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = lg.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb78ae1-aa50-41fa-9607-48a06ea7b73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit with the model \n",
    "df_test['clean_text'] = [preprocessing(s) for s in df_test['text']]\n",
    "pred = vectorizer.transform(df_test['clean_text'])\n",
    "predictions = lg.predict(pred)\n",
    "\n",
    "df_submit = pd.DataFrame({'id': df_test['id'], 'target': predictions})\n",
    "df_submit.to_csv('submission_09_09_2024.csv', index=False)\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c62c8c-a4e2-438c-856b-4c06609fa0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Logistic Regression model: was the same accuracy\n",
    "list of keywords in TfidVectorizer(): it got worsed\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2714182-4a83-4c9f-8aa9-7b5da241a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score was 0.79436"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
